Imagine you're a painter with one restriction: you can't look at the canvas while you paint. You glance at a scene for one second, turn around, and recreate it from memory. Broad strokes first, capturing what matters most. Another glance, another second, more details emerge.

This process of distilling a grand scene into its core essence while preserving the most important details is called *dimensionality reduction* in Machine Learning. An *autoencoder*, visualized here, is one such form of dimensionality reduction typically used in complex data like images, text, and audio.

Visualizing the process of perception for the first time was enthralling; juxtaposing it with human memory was even more so. 

The same image from the past starts a reconstruction process in both this autoencoder and my brain. Both reconstructions are blurry in some details, but brilliantly vivid in others.

As time goes on, memory is worn down by significance, leaving behind sentiment rather than detail.

The AI shows my friends and me smiling, wine glasses in hand. My mind reconstructs the taste of the college-budget wine, the feeling of realizing weâ€™re out of toilet paper at 2am, and the drunken thrill of stealthily grabbing heaps of TP from the nearby McDonald's bathrooms. 

The AI reconstructs a picture of my 26th birthday party. My mind reconstructs the rush from the surprise and reconnecting with friends after years on opposite coasts.

The AI converges to an accurate reconstruction.

The memory spills outside any frame.