Imagine you're a painter painting a scene on a canvas. As a restriction though, you’re not allowed to look at the canvas while you paint. You instead have to look at the scene *for just one second*, turn around, then recreate the scene on your canvas from memory. 

As a result, you start with broad strokes capturing the important details, and as you turn around and look at the canvas more, you get a better sense of the scene and can adjust the painting accordingly.

This process of distilling a grand scene into its core essence is quite beautiful. In Machine Learning, this study is formalized as *dimensionality reduction*, i.e. the process of reducing the noise in complex data. An *autoencoder*, visualized here, is one such form of dimensionality reduction. This specific one is heavily inspired by [ConvNetJS](https://cs.stanford.edu/people/karpathy/convnetjs/demo/image_regression.html), a project by Andrej Karpathy.

It’s captivating to visualize the process of perception, but especially as it relates to humans vs AI. 

With humans, as time goes on, the sharp details of the memory get eroded by its associated sentiments. The memory persists more as a collection of moments and feelings than a detailed and exact replay.

When I see an image from the past, both this autoencoder and my brain start a reconstruction process. A picture is repainted in my head and with the autoencoder, blurry in some details, yet brilliantly vivid in others.

Unlike the AI though, my head isn’t computing an exact reconstruction of the image. 

The AI reconstructs a picture of my friends and me drinking wine in an Airbnb. It won’t reconstruct the feeling of realizing we’re out of toilet paper at 2am and the drunken thrill of stealthily stealing heaps of TP from the nearby McDonalds. 

It reconstructs a picture of my 26th birthday party, but not the rush from the surprise of seeing everyone there and reconnecting with friends after years on opposite coasts.

Some memories are better that way — inexact, but vivid in the ways you reconstruct them.